{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1 Part 1 - Hayden Barker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Enter the filepath for the checkpoint : /Users/haydenbarker/Desktop/Assignment1\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/Users/haydenbarker/Desktop/Assignment1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1206da748>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Trainable Parameters :  4842\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-07-23:46:09\n",
      "INFO:tensorflow:Restoring parameters from /Users/haydenbarker/Desktop/Assignment1/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-07-23:46:10\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9884, global_step = 20000, loss = 0.0365276\n",
      "{'accuracy': 0.9884, 'loss': 0.0365276, 'global_step': 20000}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "#\"\"\"Model function for CNN.\"\"\"\n",
    "# Input Layer\n",
    "# Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "# MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "# Convolutional Layer #1\n",
    "# Computes 4 features using a 5x5 filter with ReLU activation.\n",
    "# Padding is added to preserve width and height.\n",
    "# Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "# Output Tensor Shape: [batch_size, 28, 28, 4]\n",
    "  conv1 = tf.layers.conv2d(inputs=input_layer, filters=4, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "# Pooling Layer #1\n",
    "# First max pooling layer with a 2x2 filter and stride of 2\n",
    "# Input Tensor Shape: [batch_size, 28, 28, 4]\n",
    "# Output Tensor Shape: [batch_size, 14, 14, 4]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "# Convolutional Layer #2\n",
    "# Computes 8 features using a 5x5 filter.\n",
    "# Padding is added to preserve width and height.\n",
    "# Input Tensor Shape: [batch_size, 14, 14, 4]\n",
    "# Output Tensor Shape: [batch_size, 14, 14, 8]\n",
    "  conv2 = tf.layers.conv2d(inputs=pool1, filters=8, kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "# Pooling Layer #2\n",
    "# Second max pooling layer with a 2x2 filter and stride of 2\n",
    "# Input Tensor Shape: [batch_size, 14, 14, 8]\n",
    "# Output Tensor Shape: [batch_size, 7, 7, 8]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "# Flatten tensor into a batch of vectors\n",
    "# Input Tensor Shape: [batch_size, 7, 7, 8]\n",
    "# Output Tensor Shape: [batch_size, 7 * 7 * 8]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 8])\n",
    "# Dense Layer\n",
    "# Densely connected layer with 10 neurons\n",
    "# Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "# Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=pool2_flat, units=10)\n",
    "    \n",
    "  predictions = {\n",
    "# Generate predictions (for PREDICT and EVAL mode)\n",
    "\"classes\": tf.argmax(input=logits, axis=1),\n",
    "# Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "# `logging_hook`.\n",
    "\"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  \n",
    "  print(\"Trainable Parameters : \", np.sum([np.prod(v.get_shape().as_list()) for v in tf.trainable_variables()]))\n",
    "  \n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "  \n",
    "# Calculate Loss (for both TRAIN and EVAL modes)\n",
    "# Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN: \n",
    "    loss = tf.losses.mean_squared_error(labels = labels, predictions = logits)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "  \n",
    "# Add evaluation metrics (for EVAL mode)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "  \n",
    "  eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main():\n",
    "  # get the data\n",
    "  mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "  eval_data = mnist.test.images\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32) \n",
    "  # create a session\n",
    "  sess = tf.InteractiveSession()\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  # load the checkpoint\n",
    "  # example filepath for checkpoint : /Users/haydenbarker/Desktop/Assignment1\n",
    "  filepath = input('Enter the filepath for the checkpoint : ')\n",
    "  #/Users/haydenbarker/Desktop/tensorflow-mnist-cnn-master/Part1\n",
    "  mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir = filepath)\n",
    "  # evaluate the model\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": eval_data}, y=eval_labels, num_epochs=1, shuffle=False)\n",
    "  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print(eval_results)  \n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of trainable parameters in the model is : 4842\n",
    "{'accuracy': 0.9884, 'loss': 0.0365276, 'global_step': 20000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
